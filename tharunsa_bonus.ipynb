{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "D9WBeVHWv3m4"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torchvision\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ydinz3F7q81N",
    "outputId": "5d11ce9c-ca26-486c-86d8-12a5c2ec2388"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dogs': 0, 'food': 1, 'vehicles': 2}\n"
     ]
    }
   ],
   "source": [
    "#loading and splitting the data\n",
    "\n",
    "# Image transformations\n",
    "transform = transforms.Compose([transforms.Resize((224, 224)),transforms.ToTensor()])\n",
    "\n",
    "# Loading the dataset and assigning the tagets to each class\n",
    "dataset = torchvision.datasets.ImageFolder(root='/content/dset',transform=transform)\n",
    "\n",
    "#splitting the data into train data of size 18000, and validation data and testing data of size 6000 each\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset,[18000,6000,6000])\n",
    "\n",
    "# loading the data to loader using the dataloader of torch\n",
    "traindata_loader = torch.utils.data.DataLoader(train_dataset,batch_size=64,shuffle=True)\n",
    "validationdata_loader = torch.utils.data.DataLoader(val_dataset,batch_size=64,shuffle=True)\n",
    "testdata_loader = torch.utils.data.DataLoader(test_dataset,batch_size=32,shuffle=True)\n",
    "\n",
    "# Printing the targets assignined to each class of data\n",
    "print(dataset.class_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### VGG13 model has 13 convolution layers embedded in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "nF3kF-lnwTIP"
   },
   "outputs": [],
   "source": [
    "class VGG13(nn.Module):\n",
    "    def __init__(self, in_channels=3, num_classes=3):\n",
    "        super(VGG13, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 64, kernel_size=3, padding=1),nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),nn.ReLU(inplace=True),nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),nn.ReLU(inplace=True),nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),nn.ReLU(inplace=True),nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),nn.ReLU(inplace=True),nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),nn.ReLU(inplace=True),nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        self.l1 = nn.Sequential(nn.Linear(512*7*7, 4096),nn.ReLU(),nn.Dropout(0.5))\n",
    "        self.l2 = nn.Sequential(nn.Linear(4096,4096),nn.ReLU(),nn.Dropout(0.5))\n",
    "        self.l3 = nn.Sequential(nn.Linear(4096,3)) \n",
    "    def forward(self, x):\n",
    "        output = self.features(output)\n",
    "        output = self.avgpool(output)\n",
    "        output = torch.flatten(output,1)\n",
    "        output = self.l1(output)\n",
    "        output = self.l2(output)\n",
    "        output = self.l3(output)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "T5JWpBaLwcs0"
   },
   "outputs": [],
   "source": [
    "#Loading the Alexnet to our model and using the crossEntrophyLoass() to calculate the loss in each step in epoch and SGD optimizer to update the weights\n",
    "\n",
    "classes =3\n",
    "epochs =5\n",
    "learning_rate = 0.001\n",
    "\n",
    "model = VGG13(classes).to(device)\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer=torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay = 0.005, momentum = 0.9)  \n",
    "# Train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Mr1QvFuwn8F",
    "outputId": "6a6539b6-0eb1-450f-e681-80216482f453"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final model accuracy on the 6000 testing images: 42.124989 %\n",
      "training time: 263.87313 min\n"
     ]
    }
   ],
   "source": [
    "#training the model\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "start_time= time.time()\n",
    "for epoch in range(epochs):\n",
    "    for i, (images, labels) in enumerate(traindata_loader):  \n",
    "    # loading the tensors to the device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # Forward pass the model\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        # Backward and optimize to update the weights\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "  # validating the model on the validation set images for each epoch\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images,labels in validationdata_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        dummydata, predicted = torch.max(outputs.data, 1)\n",
    "        total = total+labels.size(0)\n",
    "        correct = correct+(predicted == labels).sum().item()\n",
    "        del images, labels, outputs\n",
    "    correct1 = 0\n",
    "    total1 = 0\n",
    "\n",
    "#testing the model for the test accuracy\n",
    "correct1 = 0\n",
    "total1 = 0\n",
    "for images, labels in testdata_loader:\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    outputs = model(images)\n",
    "    dummydata, predicted = torch.max(outputs.data, 1)\n",
    "    total1 += labels.size(0)\n",
    "    correct1 += (predicted == labels).sum().item()\n",
    "    del images, labels, outputs\n",
    "print('final model accuracy on the {} testing images: {} %'.format(total1,100*correct1/total1)) \n",
    "print(\"training time: {} min\".format(round(end_time-start_time,2)/60))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WMJdgOnWsEld"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
